{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize the parameters\n",
    "'''\n",
    "DATASET = 'income' # {\"income\", \"crim-recid\", \"health\"}\n",
    "MODEL = 'main'\n",
    "DATA_LOC = './../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncomeDataset(Dataset):\n",
    "    \"\"\"Income dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.all_data = np.load(self.root_dir+file)\n",
    "        self.x = self.all_data['x']\n",
    "        self.y = self.all_data['y']\n",
    "        self.a = self.all_data['a']\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Complete all the dataset specific processing here\n",
    "        print('Income dataset (x) dims: {}'.format(self.x.shape))\n",
    "        print('Income dataset (y) dims: {}'.format(self.y.shape))\n",
    "        print('Income dataset (a) dims: {}'.format(self.a.shape))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #if torch.is_tensor(idx):\n",
    "        #    idx = idx.tolist()\n",
    "        \n",
    "        sample_x, sample_y, sample_a = np.array(self.x[idx]), np.array(self.y[idx]), np.array(self.a[idx])\n",
    "        sample_x, sample_y, sample_a = torch.tensor(sample_x, dtype=torch.float32), torch.tensor(sample_y, dtype=torch.long), torch.tensor(sample_a, dtype=torch.float32)\n",
    "\n",
    "        #print('sample_x.shape: {}'.format(sample_x.shape))\n",
    "        #print('sample_y.shape: {}'.format(sample_y.shape))\n",
    "        #print('sample_a.shape: {}'.format(sample_a.shape))\n",
    "        \n",
    "        return sample_x, sample_y, sample_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the model\n",
    "'''\n",
    "class NNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Explicit layer definition\n",
    "        \"\"\"\n",
    "        super(NNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(113, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Explicit model definition\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = NNet()\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income dataset (x) dims: (32561, 113)\n",
      "Income dataset (y) dims: (32561, 1)\n",
      "Income dataset (a) dims: (32561, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load the datasets\n",
    "'''\n",
    "if (DATASET=='income'):\n",
    "    dataset = IncomeDataset(file='adult_train.npz',\n",
    "                                    root_dir=DATA_LOC)\n",
    "    dataloader = DataLoader(dataset, batch_size=10,\n",
    "                        shuffle=True, num_workers=0)    \n",
    "elif (DATASET=='health'):\n",
    "    dataset = HealthDataset(file='processed.switzerland.data',\n",
    "                                    root_dir=DATA_LOC)\n",
    "    dataloader = DataLoader(dataset, batch_size=5,\n",
    "                        shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNet(\n",
       "  (fc1): Linear(in_features=113, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (fc3): Linear(in_features=25, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1.211029052734375\n",
      "Accuracy of the network: 66 %\n",
      "150 1.1469459533691406\n",
      "Accuracy of the network: 77 %\n",
      "250 1.0605443716049194\n",
      "Accuracy of the network: 86 %\n",
      "350 0.9465766549110413\n",
      "Accuracy of the network: 90 %\n",
      "450 0.8029006123542786\n",
      "Accuracy of the network: 92 %\n",
      "550 0.6409387588500977\n",
      "Accuracy of the network: 93 %\n",
      "650 0.4836125075817108\n",
      "Accuracy of the network: 94 %\n",
      "750 0.34897053241729736\n",
      "Accuracy of the network: 95 %\n",
      "850 0.2521102726459503\n",
      "Accuracy of the network: 95 %\n",
      "950 0.18402588367462158\n",
      "Accuracy of the network: 96 %\n",
      "1050 0.13868367671966553\n",
      "Accuracy of the network: 96 %\n",
      "1150 0.10748478025197983\n",
      "Accuracy of the network: 96 %\n",
      "1250 0.08567927032709122\n",
      "Accuracy of the network: 97 %\n",
      "1350 0.06997472047805786\n",
      "Accuracy of the network: 97 %\n",
      "1450 0.058334045112133026\n",
      "Accuracy of the network: 97 %\n",
      "1550 0.04954163730144501\n",
      "Accuracy of the network: 97 %\n",
      "1650 0.042689867317676544\n",
      "Accuracy of the network: 97 %\n",
      "1750 0.037263281643390656\n",
      "Accuracy of the network: 98 %\n",
      "1850 0.03291705623269081\n",
      "Accuracy of the network: 98 %\n",
      "1950 0.029309086501598358\n",
      "Accuracy of the network: 98 %\n",
      "2050 0.026329822838306427\n",
      "Accuracy of the network: 98 %\n",
      "2150 0.02383272908627987\n",
      "Accuracy of the network: 98 %\n",
      "2250 0.021710334345698357\n",
      "Accuracy of the network: 98 %\n",
      "2350 0.019892120733857155\n",
      "Accuracy of the network: 98 %\n",
      "2450 0.018315749242901802\n",
      "Accuracy of the network: 98 %\n",
      "2550 0.01694336161017418\n",
      "Accuracy of the network: 98 %\n",
      "2650 0.015737609937787056\n",
      "Accuracy of the network: 98 %\n",
      "2750 0.014676706865429878\n",
      "Accuracy of the network: 98 %\n",
      "2850 0.013728264719247818\n",
      "Accuracy of the network: 98 %\n",
      "2950 0.012890513986349106\n",
      "Accuracy of the network: 98 %\n",
      "3050 0.012120213359594345\n",
      "Accuracy of the network: 98 %\n",
      "3150 0.011436443775892258\n",
      "Accuracy of the network: 98 %\n",
      "3250 0.010816569440066814\n",
      "Accuracy of the network: 98 %\n",
      "3350 0.010252965614199638\n",
      "Accuracy of the network: 98 %\n",
      "3450 0.009739620611071587\n",
      "Accuracy of the network: 98 %\n",
      "3550 0.009267304092645645\n",
      "Accuracy of the network: 99 %\n",
      "3650 0.008835830725729465\n",
      "Accuracy of the network: 99 %\n",
      "3750 0.00843701884150505\n",
      "Accuracy of the network: 99 %\n",
      "3850 0.008068522438406944\n",
      "Accuracy of the network: 99 %\n",
      "3950 0.007728341966867447\n",
      "Accuracy of the network: 99 %\n",
      "4050 0.007411018945276737\n",
      "Accuracy of the network: 99 %\n",
      "4150 0.0071184756234288216\n",
      "Accuracy of the network: 99 %\n",
      "4250 0.006843951530754566\n",
      "Accuracy of the network: 99 %\n",
      "4350 0.006587563548237085\n",
      "Accuracy of the network: 99 %\n",
      "4450 0.006348255090415478\n",
      "Accuracy of the network: 99 %\n",
      "4550 0.006123415660113096\n",
      "Accuracy of the network: 99 %\n",
      "4650 0.005912100430577993\n",
      "Accuracy of the network: 99 %\n",
      "4750 0.005715027451515198\n",
      "Accuracy of the network: 99 %\n",
      "4850 0.005527685396373272\n",
      "Accuracy of the network: 99 %\n",
      "4950 0.005351260304450989\n",
      "Accuracy of the network: 99 %\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the model\n",
    "'''\n",
    "\n",
    "epochs = 5000\n",
    "total = 0\n",
    "correct = 0\n",
    "    \n",
    "for t in range(epochs):\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        x, y, a = sample_batched[0], sample_batched[1].squeeze(), sample_batched[2]\n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        #print('y_pred.dims: {}'.format(y_pred.shape))\n",
    "        #print('y.dims: {}'.format(y.shape))\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "            \n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "        if t % 100 == 50:\n",
    "            print(t, loss.item())\n",
    "            print('Accuracy of the network: %d %%' % (\n",
    "                100 * correct / total))\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrain the model (Regularize with different fairness metrics)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Train the model (Regularize with different fairness metrics)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
